# Machine Learning Algorithms from Scratch

This repository contains implementations of various machine learning algorithms from scratch using `numpy`. The goal is to provide a deeper understanding of the inner workings of these algorithms without relying on high-level libraries such as `scikit-learn`. Each algorithm is implemented with minimal external dependencies to demonstrate its foundational principles.

## Algorithms to be implemented

1. **Linear Regression**  
   - Ordinary Least Squares (OLS)
   - Shrinkage methods

2. **Logistic Regression**  
   - Binary Classification

3. **K-Nearest Neighbors (KNN)**  
   - Distance Metrics: Euclidean, Manhattan
   - Weighted Voting

4. **Support Vector Machine (SVM)**  
   - Hard Margin and Soft Margin SVM

5. **K-Means Clustering**  
   - Lloyd's Algorithm
   - Elbow Method for Optimal K

6. **Decision Trees**  
   - Gini Index and Information Gain
   - Pruning Techniques

7. **Naive Bayes Classifier**  
   - Gaussian and Multinomial Naive Bayes

8. **Principal Component Analysis (PCA)**  
   - Dimensionality Reduction
   - Eigenvalue Decomposition

9. **Neural Networks**  
   - Feedforward Neural Network
   - Backpropagation Algorithm

10. **Random Forest**  
   - Ensemble of Decision Trees
   - Bagging Technique

## Dependencies

The implementations in this repository rely primarily on `numpy` for matrix operations and linear algebra.